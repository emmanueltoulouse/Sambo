using GLib;

namespace Sambo {
    /**
     * Gestionnaire de mod√®les llama.cpp
     * G√®re le chargement, l'initialisation et la lib√©ration des mod√®les
     */
    public class ModelManager : Object {
        private static ModelManager? instance = null;
        private string current_model_path = "";
        private bool is_model_loaded = false;
        private bool is_backend_initialized = false;
        private bool is_simulation_mode = false; // Mode r√©el par d√©faut

        // Signaux pour informer l'interface
        public signal void model_loaded(string model_path, string model_name);
        public signal void model_load_failed(string model_path, string error_message);
        public signal void model_unloaded();

        /**
         * Singleton - obtenir l'instance unique
         */
        public static ModelManager get_instance() {
            if (instance == null) {
                instance = new ModelManager();
            }
            return instance;
        }

        /**
         * Constructeur priv√© (pattern singleton)
         */
        private ModelManager() {
            // Initialiser le backend llama.cpp
            init_backend();
        }

        /**
         * Initialise le backend llama.cpp
         */
        private void init_backend() {
            if (!is_backend_initialized) {
                stderr.printf("üîß MODELMANAGER: Initialisation du backend llama.cpp...\n");
                try {
                    // Tentative d'initialisation r√©elle du backend llama.cpp via wrapper
                    bool success = Llama.backend_init();
                    if (success) {
                        is_backend_initialized = true;
                        is_simulation_mode = false;
                        stderr.printf("‚úÖ MODELMANAGER: Backend llama.cpp initialis√© avec succ√®s\n");
                    } else {
                        throw new IOError.NOT_FOUND("Backend llama.cpp non disponible");
                    }
                } catch (Error e) {
                    stderr.printf("‚ö†Ô∏è MODELMANAGER: llama.cpp non disponible, mode simulation activ√©: %s\n", e.message);
                    is_simulation_mode = true;
                    is_backend_initialized = false;
                }
            }
        }

        /**
         * Charge un mod√®le depuis un fichier
         * @param model_path Chemin vers le fichier du mod√®le
         * @return true si le chargement a r√©ussi, false sinon
         */
        public bool load_model(string model_path) {
            // V√©rifier que le fichier existe
            if (!FileUtils.test(model_path, FileTest.EXISTS)) {
                string error_msg = @"Le fichier mod√®le n'existe pas : $model_path";
                warning(error_msg);
                model_load_failed(model_path, error_msg);
                return false;
            }

            // Lib√©rer le mod√®le pr√©c√©dent s'il existe
            unload_current_model();

            stderr.printf("üìÇ MODELMANAGER: Chargement du mod√®le : %s\n", model_path);

            // Mode simulation si llama.cpp n'est pas disponible
            if (is_simulation_mode) {
                return load_model_simulation(model_path);
            }

            try {
                // Tentative de chargement r√©el du mod√®le via wrapper
                bool success = Llama.load_model(model_path);
                
                if (!success) {
                    throw new IOError.FAILED("√âchec du chargement du mod√®le");
                }
                
                // Succ√®s du chargement r√©el
                current_model_path = model_path;
                is_model_loaded = true;
                
                string model_name = Path.get_basename(model_path);
                print("Mod√®le charg√© avec succ√®s : %s\n", model_name);
                
                model_loaded(model_path, model_name);
                return true;
                
            } catch (Error e) {
                // En cas d'erreur, basculer en mode simulation si possible
                warning("Erreur lors du chargement r√©el, tentative en mode simulation : %s", e.message);
                return load_model_simulation(model_path);
            }
        }

        /**
         * Charge un mod√®le en mode simulation (pour les tests sans llama.cpp)
         */
        private bool load_model_simulation(string model_path) {
            print("Mode simulation : chargement simul√© du mod√®le %s\n", model_path);
            
            // Simuler un d√©lai de chargement
            Thread.usleep(500000); // 0.5 seconde
            
            // V√©rifier la taille du fichier (simulation de validation)
            try {
                var file = File.new_for_path(model_path);
                var file_info = file.query_info(FileAttribute.STANDARD_SIZE, FileQueryInfoFlags.NONE);
                int64 file_size = file_info.get_size();
                
                if (file_size < 1024) { // Fichier trop petit
                    string error_msg = "Le fichier mod√®le semble trop petit ou corrompu";
                    model_load_failed(model_path, error_msg);
                    return false;
                }
                
                // Succ√®s de la simulation
                current_model_path = model_path;
                is_model_loaded = true;
                
                string model_name = Path.get_basename(model_path);
                print("Mod√®le simul√© charg√© avec succ√®s : %s\n", model_name);
                
                model_loaded(model_path, model_name);
                return true;
                
            } catch (Error e) {
                string error_msg = @"Erreur lors de la validation du mod√®le : $(e.message)";
                model_load_failed(model_path, error_msg);
                return false;
            }
        }

        /**
         * D√©charge le mod√®le actuel
         */
        public void unload_current_model() {
            if (is_model_loaded) {
                print("D√©chargement du mod√®le actuel...\n");
                
                if (!is_simulation_mode) {
                    // Lib√©ration des ressources llama.cpp via wrapper
                    Llama.unload_model();
                }
                
                current_model_path = "";
                is_model_loaded = false;
                
                model_unloaded();
                print("Mod√®le d√©charg√©\n");
            }
        }

        /**
         * V√©rifie si un mod√®le est actuellement charg√©
         */
        public bool is_model_ready() {
            if (is_simulation_mode) {
                return is_model_loaded;
            }
            return is_model_loaded && Llama.is_model_loaded();
        }

        /**
         * Indique si le gestionnaire fonctionne en mode simulation
         */
        public bool is_in_simulation_mode() {
            return is_simulation_mode;
        }

        /**
         * Obtient le chemin du mod√®le actuellement charg√©
         */
        public string get_current_model_path() {
            return current_model_path;
        }

        /**
         * Obtient le nom du mod√®le actuellement charg√©
         */
        public string get_current_model_name() {
            if (current_model_path == "") {
                return "";
            }
            return Path.get_basename(current_model_path);
        }

        /**
         * Destructeur - lib√®re les ressources
         */
        ~ModelManager() {
            unload_current_model();
            
            if (is_backend_initialized && !is_simulation_mode) {
                Llama.backend_free();
                is_backend_initialized = false;
            }
        }
    }
}
